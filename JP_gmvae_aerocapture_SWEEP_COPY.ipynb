{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c51b044f",
      "metadata": {
        "id": "c51b044f"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35fbbdbe",
      "metadata": {
        "id": "35fbbdbe"
      },
      "source": [
        "TO RUN:\n",
        "- Make sure to select Runtime>Change Runtime Type>T4 GPU to use cuda\n",
        "- Install pytorch_lightning\n",
        "- clone in repo to read in common files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "939cf284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "939cf284",
        "outputId": "4cd8a84a-268d-4771-abaa-32fa878bee3f",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "97517fef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97517fef",
        "outputId": "3076b39f-5a40-469a-eb0a-bdc53583a7a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "SEED = 42\n",
        "seed_everything(SEED, workers=True)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Normal\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import LightningDataModule\n",
        "import seaborn as sns\n",
        "import json\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from time import time\n",
        "import datetime\n",
        "import pickle\n",
        "import matplotlib.lines as mlines\n",
        "import sys\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "86396875",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86396875",
        "outputId": "bb3cb18f-ce90-4a25-b44a-f32c79d2e8a1",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pipag_training' already exists and is not an empty directory.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gcalkins64: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@github.com/gcalkins64/pipag_training.git\n",
        "!cd pipag_training && git pull\n",
        "sys.path.append('/content/pipag_training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6a86cb23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a86cb23",
        "outputId": "d9896afb-2822-4fe9-be1e-58b5cd5828bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2bb167c4",
      "metadata": {
        "id": "2bb167c4"
      },
      "outputs": [],
      "source": [
        "from gmvae_common import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3180eae7",
      "metadata": {
        "id": "3180eae7"
      },
      "source": [
        "# Check Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d70b1403",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d70b1403",
        "outputId": "c898372e-a5b7-4d66-97ad-551836e96bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set default tensor type to CUDA tensors\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "246109d8",
      "metadata": {
        "id": "246109d8"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af0a7be",
      "metadata": {
        "id": "9af0a7be"
      },
      "outputs": [],
      "source": [
        "n_train = 1024\n",
        "n_val = 128\n",
        "n_test = 128\n",
        "# For testing small batches of data\n",
        "# n_train = 400\n",
        "# n_val = 50\n",
        "# n_test = 50\n",
        "# THREE LAYERS\n",
        "# hd1 = 48\n",
        "# hd2 = 32\n",
        "# hd3 = 16\n",
        "# hidden_dims = [hd1, hd2, hd3]\n",
        "# TWO LAYERS\n",
        "hd1 = 32\n",
        "hd2 = 16\n",
        "hd3 = None\n",
        "hidden_dims = [hd1, hd2]\n",
        "latent_dims = [4,5,6]\n",
        "n_clustersS = [2,3,4,5,6]\n",
        "lr = 1e-3\n",
        "n_epochs = 100 # 30_000\n",
        "batch_size = 128\n",
        "em_reg = 1e-6\n",
        "decoder_var = 1e-5\n",
        "\n",
        "plot_interval = 500\n",
        "dpi = 300\n",
        "\n",
        "D = 1  #num_modalities\n",
        "downsampleNum = 64\n",
        "\n",
        "loadFlag = False  # True to load in old case, False to run a new case\n",
        "\n",
        "data = '1_near_escape_fnpag_2000_data_energy_scaled_downsampled_'\n",
        "inds = '1_near_escape_fnpag_1999_inds_energy_scaled_downsampled_'\n",
        "tag = 'near_escape'\n",
        "\n",
        "# data = '1_near_crash_fnpag_2000_data_energy_scaled_downsampled_'\n",
        "# inds = '1_near_crash_fnpag_2000_inds_energy_scaled_downsampled_'\n",
        "# tag = 'near_crash'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29af3060",
      "metadata": {
        "id": "29af3060"
      },
      "source": [
        "# LOOP GMVAE TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5f8e6f",
      "metadata": {
        "id": "cb5f8e6f"
      },
      "outputs": [],
      "source": [
        "for latent_dim in latent_dims:\n",
        "   for n_clusters in n_clustersS:\n",
        "        \n",
        "        K = n_clusters\n",
        "        Z = latent_dim\n",
        "\n",
        "        from datetime import datetime\n",
        "        timestr = datetime.strftime(datetime.now(), \"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        if loadFlag:  # Load in old data\n",
        "            dirname = os.path.join(\"drive\", \"MyDrive\", \"JP_gmvae_data\", 'gmvae_em_aerocapture_energy_20250429_155508_5_4')\n",
        "        else:  # generate new data\n",
        "            dirname = os.path.join(\"drive\", \"MyDrive\", \"JP_gmvae_data\", \"gmvae_\"+tag+\"_\"+timestr+\"_L\"+str(latent_dim)+\"_C\"+str(n_clusters))\n",
        "        os.makedirs(dirname, exist_ok=True)\n",
        "        print(\"Filepath directory: \" + dirname)\n",
        "\n",
        "        if loadFlag:  # load old data\n",
        "            postfix = '_42_1024_128_128_32_16_5_4_0.001000_128_0.001000_0.000010_1000.000000_'\n",
        "        else:  # Generate new suffix\n",
        "            if hd3 is not None:\n",
        "                postfix = '_{0:d}_{1:d}_{2:d}_{3:d}_{4:d}_{5:d}_{6:d}_{7:d}_{8:d}_{9:f}_{10:d}_{11:f}_{12:f}_{13:f}_'.format(\n",
        "                SEED, n_train, n_val, n_test, hd1, hd2, hd3, latent_dim, n_clusters, lr, batch_size, em_reg * 1e3, decoder_var, n_epochs)\n",
        "            else:\n",
        "                postfix = '_{0:d}_{1:d}_{2:d}_{3:d}_{4:d}_{5:d}_{6:d}_{7:d}_{8:f}_{9:d}_{10:f}_{11:f}_{12:f}_'.format(\n",
        "                SEED, n_train, n_val, n_test, hd1, hd2, latent_dim, n_clusters, lr, batch_size, em_reg * 1e3, decoder_var, n_epochs)\n",
        "        print(\"Filepath postfix: \" + postfix)\n",
        "\n",
        "        data_dir = os.path.join(\"drive\", \"MyDrive\", \"JP_gmvae_data\", f\"{data}.json\")\n",
        "\n",
        "        with open(os.path.join(\"drive\", \"MyDrive\", \"JP_gmvae_data\", f\"{inds}.json\"), 'r') as f:\n",
        "            sample_list_load = json.load(f)\n",
        "        sample_list = [int(sample) for sample in sample_list_load['sample_list']]\n",
        "        print(sample_list)\n",
        "\n",
        "        data_module = AerocaptureDataModuleCUDA(data_dir=data_dir, n_train=n_train, n_val=n_val, n_test=n_test,\n",
        "                                        train_batch=batch_size, val_batch=batch_size, test_batch=batch_size,\n",
        "                                        num_workers=0)\n",
        "\n",
        "        data_module.setup(\"fit\", sample_list = sample_list)\n",
        "\n",
        "        train_loader = data_module.train_dataloader()\n",
        "        val_loader = data_module.val_dataloader()\n",
        "        test_loader = data_module.test_dataloader()\n",
        "        data_dim = len(train_loader.dataset[0][0])\n",
        "        text_labels = ['capture', 'escape', 'impact']\n",
        "        label_colors = ['C2', 'C3', 'C4']\n",
        "\n",
        "        num_train_batches = len(train_loader)\n",
        "\n",
        "        ts_plot = np.linspace(0,450,64)\n",
        "        seabornSettings()\n",
        "        fig, ax = plt.subplots(figsize=(4, 4))\n",
        "        for j in range(n_train):\n",
        "            ax.plot(ts_plot, train_loader.dataset[j][0].cpu(), color=label_colors[train_loader.dataset[j][1].cpu()], alpha=0.75)\n",
        "\n",
        "        eline = mlines.Line2D([], [], color='C2', label='Escape')\n",
        "        cline = mlines.Line2D([], [], color='C3', label='Capture')\n",
        "        iline = mlines.Line2D([], [], color='C4', label='Impact')\n",
        "        plt.legend(handles=[eline, cline, iline])\n",
        "        plt.hlines(0, 0, ts_plot[-1], colors='r', linestyles='dashed')\n",
        "        plt.xlabel(\"Time [s]\")\n",
        "        plt.ylabel(\"Nondimensionalized Energy\")\n",
        "        plt.title(\"Training Data\")\n",
        "        plt.tight_layout()\n",
        "        fig.savefig(os.path.join(dirname, 'train_data'+postfix+'.png'), dpi=dpi)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        for j in range(n_val):\n",
        "            ax.plot(ts_plot, val_loader.dataset[j][0].cpu(), color=label_colors[val_loader.dataset[j][1].cpu()])\n",
        "        plt.title(\"Validation Data\")\n",
        "        fig.savefig(os.path.join(dirname, 'val_data'+postfix+'.png'), dpi=dpi)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        for j in range(n_test):\n",
        "            ax.plot(ts_plot, test_loader.dataset[j][0].cpu(), color=label_colors[test_loader.dataset[j][1].cpu()])\n",
        "        plt.title(\"Test Data\")\n",
        "        fig.savefig(os.path.join(dirname, 'test_data'+postfix+'.png'), dpi=dpi)\n",
        "        # initialize latent GMM model parameters\n",
        "        params = {}\n",
        "        pi_variables = torch.zeros(K).clone().detach().requires_grad_(True)\n",
        "        params['pi_c'] = torch.ones(K) / K\n",
        "        params['mu_c'] = torch.rand((K, Z)) * 2.0 - 1.0\n",
        "        params['logsigmasq_c'] = torch.zeros((K, Z))\n",
        "\n",
        "\n",
        "        text_labels = [f'Cluster {i}' for i in range((n_clusters))]\n",
        "        label_colors = [f'C{i+1}' for i in range((n_clusters))]\n",
        "\n",
        "        # initialize neural networks\n",
        "        encoder_list = []\n",
        "        decoder_list = []\n",
        "        trainable_parameters = []\n",
        "        trainable_parameters.append(pi_variables)\n",
        "\n",
        "        for _ in range(D):\n",
        "            encoder = Encoder(data_dim=data_dim, latent_dim=latent_dim, hidden_dims=[hd1, hd2])\n",
        "            decoder = Decoder(data_dim=data_dim, latent_dim=latent_dim, hidden_dims=[hd2, hd1], decoder_var=decoder_var)\n",
        "            encoder_list.append(encoder)\n",
        "            decoder_list.append(decoder)\n",
        "            trainable_parameters += list(encoder.parameters()) + list(decoder.parameters())\n",
        "\n",
        "        optimizer = optim.Adam(trainable_parameters, lr=lr)\n",
        "\n",
        "        # training\n",
        "\n",
        "        import time\n",
        "        ts = time.time()\n",
        "        tic = time.perf_counter()\n",
        "\n",
        "        train_loss = torch.zeros(n_epochs)\n",
        "        train_elbo_terms = torch.zeros((n_epochs, 4)) # 4 ELBO terms\n",
        "        val_elbo_terms = torch.zeros((n_epochs, 4)) # 4 ELBO terms\n",
        "        val_loss = torch.zeros(n_epochs)\n",
        "        pi_history = torch.zeros((n_epochs, K))\n",
        "        train_mse_history = torch.zeros(n_epochs)\n",
        "        val_mse_history = torch.zeros(n_epochs)\n",
        "        min_val_loss = torch.inf\n",
        "        seabornSettings()\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            ti = time.time()\n",
        "            for encoder in encoder_list:\n",
        "                encoder.train()\n",
        "            for decoder in decoder_list:\n",
        "                decoder.train()\n",
        "\n",
        "            train_elbo = 0\n",
        "            train_mse = 0\n",
        "            train_elbo_term = np.zeros(4)\n",
        "            params['hist_weights'] = torch.zeros((K, 1))\n",
        "            params['hist_mu_c'] = torch.zeros((K, latent_dim))\n",
        "            params['hist_logsigmasq_c'] = torch.zeros((K, latent_dim))\n",
        "\n",
        "            for (batch_idx, batch) in enumerate(train_loader):\n",
        "                batch_x, _ = batch\n",
        "                x_list = [batch_x]  # assume D=2 and each modality has data_dim\n",
        "                optimizer.zero_grad()\n",
        "                pi_c = torch.exp(pi_variables) / torch.sum(torch.exp(pi_variables))\n",
        "                params['pi_c'] = pi_c\n",
        "\n",
        "                mu, logsigmasq = encoder_step(x_list, encoder_list, decoder_list)\n",
        "                sigma = torch.exp(0.5 * logsigmasq)\n",
        "                eps = Normal(0, 1).sample(mu.shape)\n",
        "                z = mu + eps * sigma\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    gamma_c, mu_c, logsigmasq_c = em_step(z, mu, logsigmasq, params, em_reg, update_by_batch=True)\n",
        "                params['mu_c'] = mu_c\n",
        "                params['logsigmasq_c'] = logsigmasq_c\n",
        "\n",
        "                elbo, sse, elbo_terms = decoder_step(x_list, z, encoder_list, decoder_list, params, mu, logsigmasq, gamma_c)\n",
        "                train_elbo += elbo.item()\n",
        "                train_elbo_term += elbo_terms\n",
        "                train_mse += sse.item()\n",
        "                loss = - elbo / batch_x.shape[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            for encoder in encoder_list:\n",
        "                encoder.eval()\n",
        "            for decoder in decoder_list:\n",
        "                decoder.eval()\n",
        "\n",
        "            if epoch % plot_interval == 0 or epoch == n_epochs:\n",
        "                # Plot the first two dimensions of the latents\n",
        "                with torch.no_grad():\n",
        "                    means = []\n",
        "                    samples = []\n",
        "                    labels = []\n",
        "                    for batch in train_loader:\n",
        "                        batch_x, batch_label = batch\n",
        "                        x_list = [batch_x]\n",
        "                        mean, logsigmasq = encoder_step(x_list, encoder_list, decoder_list)\n",
        "                        sigma = torch.exp(0.5 * logsigmasq)\n",
        "                        eps = Normal(0, 1).sample(mean.shape)\n",
        "                        z = mean + eps * sigma\n",
        "                        means.append(mean)\n",
        "                        samples.append(z)\n",
        "                        labels.append(batch_label)\n",
        "\n",
        "                means = torch.vstack(means).cpu()\n",
        "                samples = torch.vstack(samples).cpu()\n",
        "                labels = torch.hstack(labels).cpu()\n",
        "\n",
        "                savepath = os.path.join(dirname, \"latent_samples_epoch_\" + str(epoch) + postfix)\n",
        "                plot_latent_space_with_clusters(samples, labels, K, mu_c.cpu(), logsigmasq_c.cpu(), savepath, text_labels, label_colors, label_colors, epoch, dpi=dpi)\n",
        "\n",
        "                savepath = os.path.join(dirname, \"latent_means_epoch_\" + str(epoch) + postfix)\n",
        "                plot_latent_space_with_clusters(means, labels, K, mu_c.cpu(), logsigmasq_c.cpu(), savepath, text_labels, label_colors, label_colors, epoch, dpi=dpi)\n",
        "\n",
        "\n",
        "                # plot samples from generative model\n",
        "                n_gen = n_train\n",
        "                cluster_probs = params['pi_c'].cpu().detach().numpy() #\n",
        "                fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "                for j in range(n_gen):\n",
        "                    c = np.random.choice(K, p=cluster_probs)\n",
        "                    mu_c = params['mu_c'][c].clone().detach()\n",
        "                    sigma_c = torch.exp(0.5 * params['logsigmasq_c'][c]).clone().detach()\n",
        "                    z = Normal(0, 1).sample(mu_c.shape) * sigma_c + mu_c\n",
        "                    mu_x = decoder.forward(z)[0]\n",
        "                    ax.plot(mu_x.cpu().detach().numpy())\n",
        "                fig.savefig(os.path.join(dirname, \"generate_samples_\" + str(epoch) + postfix+ '.png'), dpi=dpi)\n",
        "                plt.close()\n",
        "\n",
        "\n",
        "            val_elbo = 0\n",
        "            val_mse = 0\n",
        "            val_elbo_term = np.zeros(4)\n",
        "            with torch.no_grad():\n",
        "                for (batch_idx, batch) in enumerate(val_loader):\n",
        "                    batch_x, _ = batch\n",
        "                    x_list = [batch_x]\n",
        "                    mu, logsigmasq = encoder_step(x_list, encoder_list, decoder_list)\n",
        "                    sigma = torch.exp(0.5 * logsigmasq)\n",
        "                    eps = Normal(0, 1).sample(mu.shape)\n",
        "                    z = mu + eps * sigma\n",
        "                    with torch.no_grad():\n",
        "                        gamma_c, _, _ = em_step(z, mu, logsigmasq, params, em_reg)\n",
        "                    elbo, sse, elbo_items = decoder_step(x_list, z, encoder_list, decoder_list, params, mu, logsigmasq, gamma_c)\n",
        "                    val_elbo += elbo.item()\n",
        "                    val_mse += sse.item()\n",
        "                    val_elbo_term += elbo_items\n",
        "\n",
        "            train_elbo /= len(train_loader.dataset)\n",
        "            train_elbo_term = torch.tensor(train_elbo_term) / len(train_loader.dataset)\n",
        "            val_elbo /= len(val_loader.dataset)\n",
        "            val_elbo_term = torch.tensor(val_elbo_term) / len(val_loader.dataset)\n",
        "            train_mse /= len(train_loader.dataset)\n",
        "            val_mse /= len(val_loader.dataset)\n",
        "\n",
        "            tf = time.time()\n",
        "            toc = time.perf_counter()\n",
        "            print('====> Epoch: {} Train ELBO: {:.4f} Val ELBO: {:.4f}, Epoch Time (s): {:.2f}, Total Time (hrs): {:.4f}'.format(epoch, train_elbo, val_elbo, tf-ti, (toc-tic)/60/60))\n",
        "\n",
        "            train_loss[epoch] = - train_elbo\n",
        "            val_loss[epoch] = - val_elbo\n",
        "            train_elbo_terms[epoch,:] = - train_elbo_term\n",
        "            val_elbo_terms[epoch,:] = - val_elbo_term\n",
        "            pi_history[epoch] = params['pi_c']\n",
        "            train_mse_history[epoch] = train_mse\n",
        "            val_mse_history[epoch] = val_mse\n",
        "\n",
        "            if - val_elbo < min_val_loss:\n",
        "                min_val_loss = - val_elbo\n",
        "                torch.save(params['pi_c'], os.path.join(dirname, 'gmm_params_pi'+ postfix + '.pt'))\n",
        "                torch.save(params['mu_c'], os.path.join(dirname, 'gmm_params_mu'+ postfix + '.pt'))\n",
        "                torch.save(params['logsigmasq_c'], os.path.join(dirname, 'gmm_params_logsigmasq'+ postfix + '.pt'))\n",
        "                torch.save(encoder.state_dict(), os.path.join(dirname, 'encoder'+ postfix + '.pt'))\n",
        "                torch.save(decoder.state_dict(), os.path.join(dirname, 'decoder'+ postfix + '.pt'))\n",
        "\n",
        "            if epoch % plot_interval == 0 or epoch == n_epochs:\n",
        "                # Plot the training and validation loss vs. epoch number\n",
        "                plt.figure(figsize=(4.5, 4))\n",
        "            # const = min(min(train_loss), min(val_loss))\n",
        "            train_loss_adjusted = train_loss\n",
        "            val_loss_adjusted = val_loss\n",
        "            plt.plot(train_loss_adjusted.cpu()[:epoch], label='train')\n",
        "            # print(train_loss_adjusted.cpu()[:epoch])\n",
        "            plt.plot(val_loss_adjusted.cpu()[:epoch], label='val')\n",
        "            plt.yscale('symlog')\n",
        "            plt.xlabel(\"number of epochs\")\n",
        "            plt.ylabel(\"loss\")\n",
        "            plt.title(\"Negative Loss\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(dirname, 'elbo_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "            plt.close()\n",
        "\n",
        "            # Plot each term of the training loss and validation loss\n",
        "            plt.figure(figsize=(4.5, 4))\n",
        "            labels = [\"Reconstruction\", \"GMM Reg\", \"Prob Reg\", \"Encoder Var\"]\n",
        "            for ii in range(4):\n",
        "                train_loss_adjusted = train_elbo_terms[:epoch, ii]\n",
        "                val_loss_adjusted = val_elbo_terms[:epoch, ii]\n",
        "                plt.plot(train_loss_adjusted.cpu()[:epoch], label=f\"{labels[ii]}: Train\")\n",
        "                plt.plot(val_loss_adjusted.cpu()[:epoch], label=f\"{labels[ii]}: Val\", linestyle='--')\n",
        "            plt.xlabel(\"number of epochs\")\n",
        "            plt.yscale('symlog')\n",
        "            plt.ylabel(\"loss\")\n",
        "            plt.title(\"Negative Loss Terms\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(dirname, 'elbo_terms_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "            plt.close()\n",
        "\n",
        "            # Plot the training and validation mse vs. epoch number\n",
        "            plt.figure(figsize=(4.5, 4))\n",
        "            plt.semilogy(train_mse_history.cpu().detach().numpy()[:epoch], label='train')\n",
        "            plt.semilogy(val_mse_history.cpu().detach().numpy()[:epoch], label='val')\n",
        "            plt.xlabel(\"number of epochs\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(dirname, 'reconst_mse_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "            plt.close()\n",
        "\n",
        "            # Plot the history of pi\n",
        "            plt.figure(figsize=(4.5, 4))\n",
        "            for i in range(K):\n",
        "                plt.plot(pi_history[:, i].cpu().detach().numpy()[:epoch], label=r'$\\pi$' + str(i+1))\n",
        "            plt.xlabel(\"number of epochs\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(dirname, 'pi_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        te = time.time()\n",
        "        import datetime\n",
        "        duration = datetime.timedelta(seconds=te - ts)\n",
        "        print(\"Training took \", duration)\n",
        "\n",
        "        # Save off pi_history, train_loss, val_loss, train_mse_history, val_mse_history\n",
        "        torch.save(pi_history, os.path.join(dirname, 'pi_history'+ postfix + '.pt'))\n",
        "        torch.save(train_loss, os.path.join(dirname, 'train_loss'+ postfix + '.pt'))\n",
        "        torch.save(val_loss, os.path.join(dirname, 'val_loss'+ postfix + '.pt'))\n",
        "        torch.save(train_elbo_terms, os.path.join(dirname, 'train_elbo_terms'+ postfix + '.pt'))\n",
        "        torch.save(val_elbo_terms, os.path.join(dirname, 'val_elbo_terms'+ postfix + '.pt'))\n",
        "        torch.save(train_mse_history, os.path.join(dirname, 'train_mse_history'+ postfix + '.pt'))\n",
        "        torch.save(val_mse_history, os.path.join(dirname, 'val_mse_history'+ postfix + '.pt'))\n",
        "\n",
        "        if loadFlag:\n",
        "            path = dirname\n",
        "        epoch = n_epochs - 1\n",
        "        params = {}\n",
        "        encoder = Encoder(data_dim=data_dim, latent_dim=latent_dim, hidden_dims=[hd1, hd2]).to(\"cuda\")\n",
        "        decoder = Decoder(data_dim=data_dim, latent_dim=latent_dim, hidden_dims=[hd2, hd1], decoder_var=decoder_var).to(\"cuda\")\n",
        "\n",
        "        # Use if you need to load in the data\n",
        "        if loadFlag:\n",
        "            suffix = postfix\n",
        "        encoder.load_state_dict(torch.load(os.path.join(path, f'encoder_{suffix}.pt'),map_location=torch.device('cpu')))\n",
        "        decoder.load_state_dict(torch.load(os.path.join(path, f'decoder_{suffix}.pt'),map_location=torch.device('cpu')))\n",
        "        logsigmasq = torch.load(os.path.join(path, f'gmm_params_logsigmasq_{suffix}.pt'),map_location=torch.device('cpu'))\n",
        "        mu = torch.load(os.path.join(path, f'gmm_params_mu_{suffix}.pt'),map_location=torch.device('cpu'))\n",
        "        pi = torch.load(os.path.join(path, f'gmm_params_pi_{suffix}.pt'),map_location=torch.device('cpu'))\n",
        "\n",
        "        encoder_list = [encoder]\n",
        "        decoder_list = [decoder]\n",
        "\n",
        "        device = next(encoder.parameters()).device\n",
        "        # Load in training history metrics\n",
        "        pi_history = torch.load(os.path.join(dirname, 'pi_history'+ postfix + '.pt'))\n",
        "        train_loss = torch.load(os.path.join(dirname, 'train_loss'+ postfix + '.pt'))\n",
        "        val_loss = torch.load(os.path.join(dirname, 'val_loss'+ postfix + '.pt'))\n",
        "        train_elbo_terms = torch.load(os.path.join(dirname, 'train_elbo_terms'+ postfix + '.pt'))\n",
        "        val_elbo_terms = torch.load(os.path.join(dirname, 'val_elbo_terms'+ postfix + '.pt'))\n",
        "        train_mse_history = torch.load(os.path.join(dirname, 'train_mse_history'+ postfix + '.pt'))\n",
        "        val_mse_history = torch.load(os.path.join(dirname, 'val_mse_history'+ postfix + '.pt'))\n",
        "\n",
        "\n",
        "        text_labels = [f'Cluster {i}' for i in range((n_clusters))]\n",
        "        label_colors = [f'C{i+1}' for i in range((n_clusters))]\n",
        "        data_colors = label_colors\n",
        "\n",
        "        # Plot training history\n",
        "        # Plot the training and validation loss vs. epoch number\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        const = min(min(train_loss), min(val_loss))\n",
        "        # const = min(10, const)\n",
        "        train_loss_adjusted = train_loss\n",
        "        val_loss_adjusted = val_loss\n",
        "        plt.plot(train_loss_adjusted.cpu(), label='Training')\n",
        "        plt.plot(val_loss_adjusted.cpu(), label='Validation')\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Negative Loss\")\n",
        "        # plt.title(\"Negative Loss\")\n",
        "        plt.yscale('symlog')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(dirname, 'elbo_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "\n",
        "        # Plot each term of the training loss and validation loss\n",
        "        plt.figure(figsize=(4.5, 4))\n",
        "        labels = [\"Reconstruction\", \"GMM Reg\", \"Prob Reg\", \"Encoder Var\"]\n",
        "        for ii in range(4):\n",
        "            # print(train_elbo_terms.cpu()[ii, :epoch])\n",
        "            # print(len(train_elbo_terms.cpu()[ii, :epoch]))\n",
        "            train_loss_adjusted = train_elbo_terms[:, ii]\n",
        "            val_loss_adjusted = val_elbo_terms[:, ii]\n",
        "            plt.plot(train_loss_adjusted.cpu()[:], label=f\"{labels[ii]}: Train\")\n",
        "            plt.plot(val_loss_adjusted.cpu()[:], label=f\"{labels[ii]}: Val\", linestyle='--')\n",
        "        plt.xlabel(\"number of epochs\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.title(\"Negative Loss Terms\")\n",
        "        plt.yscale('symlog')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(dirname, 'elbo_terms_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "\n",
        "        # Plot the sum of each term of the training loss and validation loss\n",
        "        plt.figure(figsize=(4.5, 4))\n",
        "        # print(train_elbo_terms.cpu()[ii, :epoch])\n",
        "        # print(len(train_elbo_terms.cpu()[ii, :epoch]))\n",
        "        train_loss_adjusted = train_elbo_terms.sum(axis=1)\n",
        "        val_loss_adjusted = val_elbo_terms.sum(axis=1)\n",
        "        plt.plot(train_loss_adjusted.cpu()[:], label=f\"Train\")\n",
        "        plt.plot(val_loss_adjusted.cpu()[:], label=f\"Val\", linestyle='--')\n",
        "        plt.xlabel(\"number of epochs\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.title(\"Sum of ELBO Terms\")\n",
        "        plt.yscale('symlog')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(dirname, 'elbo_terms_sum_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "        # Plot the training and validation mse vs. epoch number\n",
        "        plt.figure(figsize=(4.5, 4))\n",
        "        plt.semilogy(train_mse_history.cpu().detach().numpy(), label='train')\n",
        "        plt.semilogy(val_mse_history.cpu().detach().numpy(), label='val')\n",
        "        plt.xlabel(\"number of epochs\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(dirname, 'reconst_mse_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "        # Plot the history of pi\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        for i in range(K):\n",
        "            plt.plot(pi_history[:, i].cpu().detach().numpy(), label=text_labels[i]+r' $\\pi$', color=label_colors[i])\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Predicted Cluster Probability\")\n",
        "        plt.axhline(y=0.05, color='C1', linestyle='--', label='True Escape Probability')\n",
        "        plt.axhline(y=0.95, color='C3', linestyle='--', label='True Capture Probability')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(dirname, 'pi_'+ str(epoch)+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "        # Load best model saved\n",
        "        params['pi_c'] = torch.load(os.path.join(dirname, 'gmm_params_pi'+ postfix + '.pt'))\n",
        "        params['mu_c'] = torch.load(os.path.join(dirname, 'gmm_params_mu'+ postfix + '.pt'))\n",
        "        params['logsigmasq_c'] = torch.load(os.path.join(dirname, 'gmm_params_logsigmasq'+ postfix + '.pt'))\n",
        "        encoder.load_state_dict(torch.load(os.path.join(dirname, 'encoder'+ postfix + '.pt')))\n",
        "        decoder.load_state_dict(torch.load(os.path.join(dirname, 'decoder'+ postfix + '.pt')))\n",
        "\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        # run one last EM step and plot training data in latent space\n",
        "        for encoder in encoder_list:\n",
        "            encoder.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            means = []\n",
        "            samples = []\n",
        "            labels = []\n",
        "            params['hist_weights'] = torch.zeros((K, 1))\n",
        "            params['hist_mu_c'] = torch.zeros((K, latent_dim))\n",
        "            params['hist_logsigmasq_c'] = torch.zeros((K, latent_dim))\n",
        "            for batch in train_loader:\n",
        "                batch_x, batch_label = batch\n",
        "                x_list = [batch_x]\n",
        "                mu, logsigmasq = encoder_step(x_list, encoder_list, decoder_list)\n",
        "                sigma = torch.exp(0.5 * logsigmasq)\n",
        "                eps = Normal(0, 1).sample(mu.shape)\n",
        "                z = mu + eps * sigma\n",
        "                with torch.no_grad():\n",
        "                    gamma_c, mu_c, logsigmasq_c = em_step(z, mu, logsigmasq, params, em_reg, update_by_batch=True)\n",
        "                params['mu_c'] = mu_c\n",
        "                params['logsigmasq_c'] = logsigmasq_c\n",
        "\n",
        "                means.append(mu)\n",
        "                samples.append(z)\n",
        "                labels.append(batch_label)\n",
        "\n",
        "        means = torch.vstack(means).cpu()\n",
        "        samples = torch.vstack(samples).cpu()\n",
        "        labels = torch.hstack(labels).cpu()\n",
        "\n",
        "\n",
        "        savepath = os.path.join(dirname, \"BEST_latent_samples\"+postfix)\n",
        "        plot_latent_space_with_clusters(samples, labels, K, mu_c.cpu(), logsigmasq_c.cpu(), savepath, text_labels, label_colors, data_colors, dpi=dpi)\n",
        "\n",
        "        savepath = os.path.join(dirname, \"BEST_latent_means\"+postfix)\n",
        "        plot_latent_space_with_clusters(means, labels, K, mu_c.cpu(), logsigmasq_c.cpu(), savepath, text_labels, label_colors, data_colors, dpi=dpi)\n",
        "\n",
        "        # plot test data in latent space\n",
        "        with torch.no_grad():\n",
        "            test_means = []\n",
        "            test_labels = []\n",
        "            for batch in test_loader:\n",
        "                batch_x, batch_label = batch\n",
        "                x_list = [batch_x]\n",
        "                mean, _ = encoder_step(x_list, encoder_list, decoder_list)\n",
        "                test_means.append(mean)\n",
        "                test_labels.append(batch_label)\n",
        "\n",
        "        test_means = torch.vstack(test_means).cpu()\n",
        "        test_labels = torch.hstack(test_labels).cpu()\n",
        "\n",
        "\n",
        "        savepath = os.path.join(dirname, \"BEST_test_latent_samples\"+postfix)\n",
        "        plot_latent_space_with_clusters(test_means, test_labels, K, mu_c.cpu(), logsigmasq_c.cpu(), savepath, text_labels, label_colors, data_colors, dpi=dpi)\n",
        "\n",
        "        # plot decoding results from cluster means # todo: expand this function for multi-modal data\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        for i in range(K):\n",
        "            # with torch.no_grad:\n",
        "            x_mean = decoder.forward(params['mu_c'][i])[0]\n",
        "            ax.plot(x_mean.cpu().detach().numpy(), label=\"decoded $\\mu$\"+str(i+1))\n",
        "        ax.legend()\n",
        "        plt.title(\"Decoded Means\")\n",
        "        fig.savefig(os.path.join(dirname, \"BEST_decoded_means\"+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "        # plot samples from generative model\n",
        "        n_gen = n_train\n",
        "        cluster_probs = params['pi_c'].cpu().detach().numpy()\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        for j in range(n_gen):\n",
        "            c = np.random.choice(K, p=cluster_probs)\n",
        "            # print(c)\n",
        "            mu_c = params['mu_c'][c].cpu().clone().detach()\n",
        "            sigma_c = torch.exp(0.5 * params['logsigmasq_c'][c]).cpu().clone().detach()\n",
        "            z = Normal(0, 1).sample(mu_c.shape).cpu().clone().detach() * sigma_c + mu_c\n",
        "            # print(z)\n",
        "            mu_x = decoder.forward(z.cuda())[0].cpu().clone().detach()\n",
        "            sigma_x = torch.exp(0.5 * decoder.forward(z.cuda())[1])\n",
        "            sample_x = Normal(0, 1).sample(mu_x.shape).cpu().clone().detach() * sigma_x.cpu().clone().detach() + mu_x\n",
        "            ax.plot(sample_x.cpu().detach().numpy())\n",
        "        plt.title(\"Generated Samples\")\n",
        "        fig.savefig(os.path.join(dirname, \"BEST_generate_samples\"+postfix+'.png'), dpi=dpi)\n",
        "        # plt.close()\n",
        "\n",
        "        np.savez(dirname + postfix, train_loss=train_loss.cpu().detach().numpy(), val_loss=val_loss.cpu().detach().numpy(),\n",
        "            train_mse=train_mse_history.cpu().detach().numpy(), val_mse=val_mse_history.cpu().detach().numpy(),\n",
        "            pi_history=pi_history.cpu().detach().numpy(),\n",
        "            cluster_probs=params['pi_c'].cpu().detach().numpy(),\n",
        "            cluster_means=params['mu_c'].cpu().detach().numpy(),\n",
        "            cluster_vars=torch.exp(params['logsigmasq_c']).cpu().detach().numpy())\n",
        "\n",
        "\n",
        "        print(\"Training data size\", n_train)\n",
        "        print(\"Fraction of downward curves:\", (torch.sum(labels == 0) / n_train).item())\n",
        "        print(\"Cluster 1 probability:\", cluster_probs.min().item())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0917a93c35e642ca9095689668d52855": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1339490bf9354b3a87ca24cb058c5955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d955c6f623e49e880042fe250747aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4adc9a7c6d6849ea880b605317fa2cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60485649fb5548e4b9af258e7f126847",
            "max": 1280,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac1bfef47b8b468c8cdc16a1c8c9e8ac",
            "value": 1280
          }
        },
        "60485649fb5548e4b9af258e7f126847": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf35a3b7c3b46478545b7a8c0c59fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0917a93c35e642ca9095689668d52855",
            "placeholder": "",
            "style": "IPY_MODEL_d92e7161536141d09dcc54002209ad64",
            "value": "100%"
          }
        },
        "6ded9fde0af54fe6b6b70e48661e68c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7329ad5f2eb4cb0bab38ed2d0e078e3",
            "placeholder": "",
            "style": "IPY_MODEL_1d955c6f623e49e880042fe250747aa3",
            "value": "1280/1280[00:00&lt;00:00,12232.75it/s]"
          }
        },
        "ac1bfef47b8b468c8cdc16a1c8c9e8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c787374adde749bb8477bd71bfd45667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bf35a3b7c3b46478545b7a8c0c59fb3",
              "IPY_MODEL_4adc9a7c6d6849ea880b605317fa2cbc",
              "IPY_MODEL_6ded9fde0af54fe6b6b70e48661e68c4"
            ],
            "layout": "IPY_MODEL_1339490bf9354b3a87ca24cb058c5955"
          }
        },
        "d92e7161536141d09dcc54002209ad64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7329ad5f2eb4cb0bab38ed2d0e078e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
